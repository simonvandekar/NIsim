---
title: "Documentation for running pbj simulations on AWS"
author: "Simon Vandekar"
date: "2/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
path = Sys.getenv('PATH')
path = Sys.setenv('PATH'=paste(path, '/home/rstudio/.local/bin', sep=':'))
```

## AWS machine image setup

I use the directions [here](https://jagg19.github.io/2019/08/aws-r/#short-easy) to create an AMI to run Rstudio on.
The `Welcome.R` script in the [NIsim](https://github.com/simonvandekar/NIsim) package has code to setup this machine image with Dropbox access to the files.


## Setup simulations

```{r, eval=FALSE}
### LIBRARIES ###
library(RNifti)
library(parallel)
library(splines)
library(mmand)
library(fslr)
library(progress)
library(abind)
library(pbj)





### LOAD IN DATA FROM DROPBOX ###
dbimagedir = '~/Dropbox/pbj/data/abide/neuroimaging/cpac/alff'
dbresimagedir = '~/Dropbox/pbj/data/abide/neuroimaging/cpac/alff_resid'
dbdatafile = '~/Dropbox/pbj/data/abide/demographic/n1035_phenotypic_20190509.rds'
maskfile = '~/Dropbox/pbj/data/abide/neuroimaging/MNI152_T1_3mm.nii.gz'


# load in data and get directories
dat = readRDS(dbdatafile)
# fake covariates for later use if needed
dat$fake_covariate = rnorm(nrow(dat))
dat$fake_group = factor(sample(1:4, nrow(dat), replace=TRUE))
dat$imgname = paste(dat$file_id, 'alff.nii.gz', sep='_')
dat$images = file.path(dbimagedir, dat$imgname)



### COMPUTING PARAMETERS ###
computeConfig = list(
  # number of cores to use for computing
  ncores = 1
)




### SIMULATION PARAMETERS ###
simConfig = list(
  # use robust variance estimator?
  robust = TRUE,
  # what transformation to use. Only the first is used
  tranform = c('t', 'edgeworth', 'none'),
  # vector of sample sizes to simulate
  ns = c(50, 100, 200, 400),
  # number of simulations to run
  nsim=100,
  # number of bootstraps
  nboot = 0,
  # number of permutations
  nperm = 0,
  # cluster forming thresholds
  cfts.s = c(0.1, 0.25, 0.4),
  cfts.p = c(0.05, 0.01, 0.005, 0.001),
  
  # radius for spheres of signal.
  rs=c(8),
  
  #### MODEL FORMULAS FOR SIMULATIONS ####
  formres = as.formula( paste0(" ~ dx_group + sex + func_mean_fd + ns(age_at_scan, df=10)" )),
  # need age_at_scan in both models for testing nonlinear functions
  form = as.formula(paste0(" ~ sex + func_mean_fd + age_at_scan + scale(age_at_scan^2) + scale(age_at_scan^3)" )),
  formred = as.formula(paste0(" ~ sex + func_mean_fd + age_at_scan")),
  #  weights for each subject. Can be a character vector
  W = c("func_mean_fd"),
  # where to output results
  outdir = '~/spline_nullsim',
  dat = dat,
  mask = maskfile
)
# use betas = 0 for global null
# parameters = betas * sd(y)/sd(x).
simConfig$betas = rep(0, length(simConfig$rs))



### SETUP THE SIMULATION ANALYSIS ###
# subsets dataset to all people who have the variables
simConfig$dat = simConfig$dat[apply(!is.na(simConfig$dat[ ,c(all.vars(as.formula(simConfig$formres)), simConfig$W)]), 1, all), ]
if(class(simConfig$formres)=='formula' | is.character(simConfig$formres)){
  simConfig$dat$rfiles = file.path(tempdir(), 'res_images', basename(simConfig$dat$images))
  pbj::residualizeImages(files=simConfig$dat$images, dat=simConfig$dat, mask=simConfig$mask, form=simConfig$formres,
                         outfiles=simConfig$dat$rfiles, mc.cores=computeConfig$ncores)
  simConfig$dat$images = simConfig$dat$rfiles
  # clean up. May not be necessary
  gc()
}



debug(NIsim::simSetup)
simSetup(simConfig$dat$images, data, outdir, nsim=1000, ns=c(50,100, 200, 400), mask=NULL, rs=8, betas=rep(0, length(rs)) )






```


## Create AWS spot fleet with Redis workers

This is experimental code to spin-up a spot machine on AWS that can be used to run the simulations.
```{r, setupAWSjson}
# output name of the json config file -- THIS FILE WILL BE MADE OR OVERWRITTEN
createLaunchJSON = '/home/rstudio/dropbox/aws/ec2/create_launch_template_jsons/pbjWorkers.json'
# get host ip address
createLaunchTemplateJSON = '/home/rstudio/dropbox/aws/ec2/create_launch_template_jsons/pbjWorkersTemplate.json'
#readLines(templatejson)

# get commands for UserData field
userdata = tempfile()
userdatacmds = paste("#!/bin/bash; R --file=~/home/ubuntu/start_redis_workers.R --args", host, queuename, collapse=' ' )
fileConn = file(tmpfile)
writeLines(userdata, fileConn)
close(fileConn)
#userdata = system(paste('base64', tmpfile), intern=TRUE)
# the host argument location is identified by the string ###HOST###
system(paste0('sed s+###USERDATA###+',tmpfile, '+ ', createLaunchTemplateJSON, ' > ', createLaunchJSON))
```

```{r, createLaunchTemplate}
# create spot instances
aws ec2 run-instances --image-id ami-09b4d361c6a48c1d5 --count 2 --instance-type t2.micro --key-name redisServer --user-data file:///tmp/Rtmpm5qHyi/file10a178470db --instance-market-options file:///home/rstudio/dropbox/aws/ec2/market_type/specification.json
# copy pem file over to spot instances

# update and install sshfs
# map dropbox drive from spot instances
```


```{r, createFleet, eval=FALSE}
# createFleet json config file
#createFleetJSON = '/home/rstudio/dropbox/aws/ec2/create_fleet_jsons/pbjWorker.json'
#fleetJSON = system(paste0('aws ec2 create-fleet --cli-input-json file://', createFleetJSON), intern=TRUE )
#requestSpotInstancesJSON = '/home/rstudio/dropbox/aws/ec2/request_spot_instances/request_little_spot_instances.json'
#spotsJSON = system(paste0('aws ec2 request-spot-instances --cli-input-json file://', requestSpotInstancesJSON), intern=TRUE )
#aws ec2 request-spot-instances --instance-count 2 --type "one-time" --launch-specification file:///home/rstudio/dropbox/aws/ec2/request_spot_instances/specification.json
# run for loop
# close fleet
```
